# -*- coding:utf-8 -*-
# Anaconda 4.3.0 環境

import numpy
import pandas
import matplotlib.pyplot as plt

# scikit-learn ライブラリ関連
from sklearn.preprocessing import StandardScaler        # scikit-learn の preprocessing モジュールの StandardScaler クラス
from sklearn.svm import SVC                             # 

from sklearn.model_selection import cross_val_score     #
from sklearn.model_selection import StratifiedKFold     #
from sklearn.model_selection import GridSearchCV        # 

from sklearn.metrics import accuracy_score              # 
from sklearn.metrics import roc_curve                   # ROC曲線
from sklearn.metrics import auc                         # AUC

from sklearn.pipeline import Pipeline

# 自作クラス
from MLPlot import MLPlot                               # 機械学習の plot 処理群を表すクラス
from MLPreProcess import MLPreProcess                   # 機械学習の前処理群を表すクラス


def main():
    """
    XOR データの SVM による２クラス識別
    ・機械学習パイプラインによる、機械学習処理フローで実装（scikit-learn ライブラリの Pipeline クラスを使用）
    ・クロス・バディゲーションによる汎化性能の確認
    ・グリッドサーチによるハイパーパラメータのチューニング
    ・識別境界の表示
    """
    print("Enter main()")
    
    # データの読み込み
    #X_features, y_labels = 

    #----------------------------------------------------
    #   XOR data read & set  data (randam data)
    #----------------------------------------------------
    # 乱数の seed
    numpy.random.seed(0)

    # 標準正規分布に従う乱数で row:200, col:2 の行列生成
    X_features = numpy.random.randn( 200, 2 )

    # X_features を XORした結果でクラス分けする
    y_labels = numpy.logical_xor( 
                (X_features[:,0] > 0),  # １列目と２列目どちらかが正と成るか？
                (X_features[:,1] > 0)
            )   
    
    y_labels = numpy.where( y_labels > 0 , 1, -1 )

    #===========================================
    # 前処理 [PreProcessing]
    #===========================================
    # データをトレードオフデータとテストデータに分割
    X_train, X_test, y_train, y_test \
    = MLPreProcess.dataTrainTestSplit( X_input = X_features, y_input = y_labels, ratio_test = 0.3 )
    #
    stdScaler = StandardScaler()
    
    # X_train の平均値と標準偏差を計算
    stdScaler.fit( X_train )

    # 求めた平均値と標準偏差を用いて標準化
    X_train_std = stdScaler.transform( X_train )
    X_test_std  = stdScaler.transform( X_test )

    # 分割したデータを行方向に結合（後で plot データ等で使用する）
    X_combined_std = numpy.vstack( (X_train_std, X_test_std) )  # list:(X_train_std, X_test_std) で指定
    y_combined     = numpy.hstack( (y_train, y_test) )

    #-------------------------------------
    # サンプルデータの図示
    #-------------------------------------
    """
    # plt.subplot(行数, 列数, 何番目のプロットか)
    plt.subplot(1,2,1)

    plt.grid(linestyle='-')

    # class +1 plot(赤の□)
    plt.scatter(
        X_features[ y_labels == 1, 0 ], X_features[ y_labels == 1 , 1 ],
        color = "red",
        edgecolor = 'black',
        marker = "s",
        label = "1"
    )
    # class -1 plot(青のx)
    plt.scatter(
        X_features[ y_labels == -1, 0 ], X_features[ y_labels == -1 , 1 ],
        color = "blue",
        edgecolor = 'black',
        marker = "x",
        label = "-1"
    )

    plt.title("XOR data (generated by ramdam Normal Disuturibution)")     # title
    plt.xlim( [-3,3] )
    plt.ylim( [-3,3] )
    plt.legend(loc = "upper left")              # 凡例    
    #plt.tight_layout()                          # グラフ同士のラベルが重ならない程度にグラフを小さくする。
    plt.savefig("./SVM_4-1.png", dpi = 150, bbox_inches = 'tight' )
    #plt.show()
    """
    

    #-------------------------------------------
    # Pipeline の設定
    #-------------------------------------------
    clf_svm = SVC( 
        kernel = 'rbf',     # rbf : RFBカーネルでのカーネルトリックを指定
        gamma = 0.1,       # RFBカーネル関数のγ値
        C = 1000,            # C-SVM の C 値
        random_state = 0,   #
        probability = True  # 学習後の predict_proba method による予想確率を有効にする
    )


    # パイプラインに各変換器、推定器を設定
    pipe_csvm = Pipeline(
                      steps = [                                     # タプル (任意の識別文字, 変換器 or 推定器のクラス) で指定
                                  ( "scl", StandardScaler() ),      # 正規化 : 変換器のクラス（fit() 関数を持つ）
                                  ('clf', clf_svm )                 # C-SVM : 推定器のクラス（predict()関数を持つ）
                              ]
                  )

    # pipeline オブジェクトの内容確認
    print( "Pipeline.get_params() : \n", pipe_csvm.get_params( deep = True ) )
    print( "Pipeline.get_params() : \n", pipe_csvm.get_params( deep = False ) )

    #===========================================
    # チューニング
    #===========================================
    #------------------------------------
    # grid search
    #------------------------------------
    # グリッドサーチの対象パラメータ : 今の場合 C=SVM の正規化パラメータ C 値とガンマ値
    param_range_C = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
    param_range_gamma = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]

    # グリッドサーチでチューニングしたいモデルとそのパラメータ : ディクショナリ（辞書）のリストで指定
    param_grid = [
        { 'clf__C': param_range_C, 'clf__kernel': ['linear'] },                                # liner C-SVM
        { 'clf__C': param_range_C, 'clf__gamma': param_range_gamma, 'clf__kernel': ['rbf'] }   # RBF-kernel C-SVM
    ]

    # グリッドサーチを行う,GridSearchCV クラスのオブジェクト作成
    gs = GridSearchCV(
            estimator = pipe_csvm,      # 推定器
            param_grid = param_grid,    # グリッドサーチの対象パラメータ
            scoring = 'accuracy',       # 
            cv = 10,                    # クロスバディゲーションの回数
            n_jobs = -1                 # 全てのCPUで並列処理
         )
    # グリッドサーチを行う
    gs = gs.fit( X_train, y_train )

    cv_keys = ('mean_test_score', 'std_test_score','params')
    for r, _ in enumerate( gs.cv_results_['mean_test_score'] ):
        print("%0.3f +/- %0.2f %r"
              % (gs.cv_results_[cv_keys[0]][r], 
                 gs.cv_results_[cv_keys[1]][r] / 2.0, 
                 gs.cv_results_[cv_keys[2]][r]))
    
    print('Best parameters: %s' % gs.best_params_)
    print('Accuracy: %.2f' % gs.best_score_)


    # グリッドサーチの結果を print
    print( "sklearn.model_selection.GridSearchCV.best_score_ : \n", gs.best_score_ )        # 指定したモデルの内, 最もよいスコアを出したモデルのスコア
    print( "sklearn.model_selection.GridSearchCV.best_params_ : \n", gs.best_params_ )      # 最もよいスコアを出したモデルのパラメータ
    #print( "sklearn.model_selection.GridSearchCV.grid_scores_ : \n",gs.grid_scores_ )       # 全ての情報
    
    # 最もよいスコアを出したモデルを抽出し, テストデータを評価
    clf = gs.best_estimator_
    clf.fit( X_train, y_train )     # 抽出したモデルをトレーニングデータで学習
    print('sklearn.model_selection.GridSearchCV.best_estimator_ in Test accuracy: %.3f' % clf.score( X_test, y_test ) )     # 最もよいスコアを出したモデルでのテストデータ

    #-----------------------------------------------
    # グリッドサーチのためのヒートマップ図の plot
    #-----------------------------------------------
    # 再設定：RBF-kernel SVM
    param_grid = [
        { 'clf__C': param_range_C, 'clf__gamma': param_range_gamma, 'clf__kernel': ['rbf'] }    # RBF-kernel C-SVM
    ]

    # グリッドサーチを行う,GridSearchCV クラスのオブジェクト作成
    gs = GridSearchCV(
            estimator = pipe_csvm,      # 推定器
            param_grid = param_grid,    # グリッドサーチの対象パラメータ
            scoring = 'accuracy',       # 
            cv = 10,                    # クロスバディゲーションの回数
            n_jobs = -1                 # 全てのCPUで並列処理
         )

    # グリッドサーチを行う
    gs = gs.fit( X_train, y_train )

    # grid_scores_ 属性から正解率を抽出
    gs_params = []
    gs_mean_scores = []
    gs_scores = []

    for parames, mean_score, scores in gs.grid_scores_:
        gs_params.append( parames )
        gs_mean_scores.append( mean_score )
        gs_scores.append( scores )
    
    
    gs_mean_scores = numpy.reshape( gs_mean_scores , ( len(param_range_C), len(param_range_gamma) ) )
    #gs_scores = numpy.reshape( gs_scores , (8,8) )

    #print( "sklearn.model_selection.GridSearchCV.grid_scores_.parmes : \n", gs_params )
    #print( "sklearn.model_selection.GridSearchCV.grid_scores_.mean_scores : \n", gs_mean_scores )
    #print( "sklearn.model_selection.GridSearchCV.grid_scores_.scores : \n", gs_scores )

    # ヒートマップのためのデータ
    heatmap_Z = gs_mean_scores
    heatmap_x = param_range_gamma
    heatmap_y = param_range_C
    
    # ヒートマップを作図
    plt.clf()
    MLPlot.drawHeatMapFromGridSearch(
        dat_Z = heatmap_Z,        # ヒートマップの値 : RBF-kernel SVM での正解率
        dat_x = heatmap_x,        # x 軸の目盛り
        dat_y = heatmap_y         # y 軸の目盛り
    )
    
    plt.title("Heat Map (Grid Search) \n values : Accuracy , classifiler : RBF-kernel SVM, CV=10 ")
    plt.ylabel( "C : RBF-kernel SVM parametor" )
    plt.xlabel( "gamma : RBF-kernel parametor" )

    plt.savefig("./SVM_4-2.png", dpi = 300, bbox_inches = 'tight' )
    plt.show()


    #===========================================
    # Learning Process
    #===========================================
    # パイプラインに設定した変換器の fit() 関数を実行
    pipe_csvm.fit( X_train, y_train )
    print( "Test Accuracy: %.3f" % pipe_csvm.score( X_test, y_test ) )


    #===========================================
    # 汎化性能の確認
    #===========================================
    # パイプラインに設定した推定器の predict() 実行
    y_predict = pipe_csvm.predict(X_test)
    print("predict : ", y_predict )

    #-------------------------------------------
    # 識別境界
    #-------------------------------------------
    plt.clf()
    MLPlot.drawDiscriminantRegions( 
        X_features = X_combined_std, y_labels = y_combined,
        classifier = clf_svm,
        list_test_idx = range( 101,150 )
    )
    plt.title("Idification Result (γ=0.001 C=1000)")     # title
    plt.xlim( [-3,3] )
    plt.ylim( [-3,3] )
    plt.legend(loc = "upper left")              # 凡例  
    plt.savefig("./SVM_4-3.png", dpi = 300, bbox_inches = 'tight' )
    plt.show()

    #-------------------------------------------
    # 正解率, 誤識率
    #-------------------------------------------
    # k-fold CV を行い, cross_val_score( scoring = 'accuracy' ) で 正解率を算出
    print( "[Accuracy]")

    # train data
    scores = cross_val_score(
                estimator = pipe_csvm,  # 推定器 [estimator]
                X = X_train_std,              #
                y = y_train,              #
                cv = 10,                  # 交差検証の回数（分割数）
                scoring = 'accuracy',    # 正解率
                n_jobs = -1               # 全てのCPUで並列処理
             )

    print( 'CV accuracy scores [train]: %s' % scores )
    print( 'CV accuracy [train]: (%.3f +/- %.3f)' % ( scores.mean(), scores.std() ) )

    # test data
    scores = cross_val_score(
                estimator = pipe_csvm,  # 推定器 [estimator]
                X = X_test_std,              #
                y = y_test,              #
                cv = 10,                  # 交差検証の回数（分割数）
                scoring = 'accuracy',    # 正解率
                n_jobs = -1               # 全てのCPUで並列処理
             )

    print( 'CV accuracy scores [test]: %s' % scores )
    print( 'CV accuracy [test]: (%.3f +/- %.3f)' % ( scores.mean(), scores.std() ) )

    #-------------------------------------------
    # AUC 値
    #-------------------------------------------
    # k-fold CV を行い, cross_val_score( scoring = 'roc_auc' ) で AUC を算出
    print( "[AUC]")

    # train data
    scores = cross_val_score(
                 estimator = pipe_csvm,
                 X = X_train_std,
                 y = y_train,
                 cv = 10,
                 scoring = 'roc_auc'    # AUC
             )
    
    print( "AUC <train data> : %0.3f (+/- %0.3f) [train]" % ( scores.mean(), scores.std() ) )

    # test data
    scores = cross_val_score(
                 estimator = pipe_csvm,
                 X = X_test_std,
                 y = y_test,
                 cv = 10,
                 scoring = 'roc_auc'    # AUC
             )

    print( "AUC <test data> : %0.3f (+/- %0.3f) [test]" % ( scores.mean(), scores.std() ) )



    print("Finish main()")
    return


if __name__ == '__main__':
     main()